{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0af4199",
   "metadata": {},
   "source": [
    "üéØLinear regression is a fundamental statistical technique used to predict the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship between the variables, enabling us to estimate the value of the dependent variable based on the independent variables. In the case of predicting car fuel efficiency, linear regression proves to be an effective tool.\n",
    "üîç Here is a step-by-step solution on how I built the model:\n",
    "1Ô∏è‚É£ Data Collection: The first step involved gathering the Car Auto MPG dataset, which contains information about various car attributes such as horsepower, weight, cylinders, and miles per gallon (MPG).\n",
    "2Ô∏è‚É£ Data Preprocessing: I performed a comprehensive analysis of the dataset, checking for missing values, outliers, and inconsistencies. Then, I conducted feature engineering to select relevant independent variables and prepared the data for model training.\n",
    "3Ô∏è‚É£ Splitting the Data: To evaluate the performance of the model accurately, I divided the dataset into a training set and a testing set. The training set was used to train the model, while the testing set helped assess its predictive capabilities.\n",
    "4Ô∏è‚É£ Model Building: With the dataset prepared, I employed linear regression, a supervised learning algorithm, to train the model. This involved finding the optimal coefficients for each independent variable to create a linear equation that best predicts car fuel efficiency.\n",
    "5Ô∏è‚É£ Model Evaluation: To evaluate the accuracy and robustness of the model, I used various evaluation metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared. These metrics provided insights into how well the model fitted the data.\n",
    "6Ô∏è‚É£ Predictions: Once the model was trained and evaluated, I utilized it to make predictions on unseen data, i.e., the testing set. Comparing the predicted MPG values with the actual values allowed me to assess the model's performance on new data.\n",
    "7Ô∏è‚É£ Model Refinement: Finally, I iteratively refined the model by tweaking hyperparameters, trying different feature combinations, or exploring alternative algorithms to enhance its predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea121636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import linear regression machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# importing ploting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the CSV file into pandas dataframe\n",
    "mpg_df = pd.read_csv('car-mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2075d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check top few records to get a feel of thr data structure \n",
    "mpg_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f42e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the car name column as it is useless for the model\n",
    "mpg_df = mpg_df.drop('car_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2debe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dba0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the numbers in categorical variables with the actual country names in the origin col\n",
    "mpg_df['origin'] = mpg_df['origin'].replace({1: 'america', 2:'europe', 3:'asia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e958d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variable into dummy/indicator variable. as many columns will be created as distinct values\n",
    "# this is also known as one hot encoding. thw column name will be america, europe, and asia.... with one hot coding\n",
    "mpg_df = pd.get_dummies(mpg_df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d05af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analyze the distribution of the dependent (mpg) column\n",
    "mpg_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f574a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd324a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: HP column is missing the descibe output. That indicates something is not right with that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the hp column contains anything other than digits\n",
    "# run the \"isdigit() check on 'hp' column of the mpg_df dataframe. result will be True or False for every row\"\n",
    "# capture the result in temp dataframe and row a frequency count using value_counts()\n",
    "# there are six records with non digit values in 'hp' column \n",
    "\n",
    "temp = pd.DataFrame(mpg_df.hp.str.isdigit())      # if the string is made of digit store True else False in the hp column\n",
    "# in the temp dataframe\n",
    "\n",
    "temp[temp['hp'] == False]   # from temp take only those where hp has false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on inspecting records number 32, 126, etc we fing \"?\" in the columns. replace them with \"nan\"\n",
    "# replace them with nan and remove the records from the data frame that have \"nan\" \n",
    "mpg_df = mpg_df.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b500ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see if we can get those records with nan\n",
    "mpg_df[mpg_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are various ways to handle missing values. drop the rows, replace missing values with median values etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f495d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of the 398 rows 6 have NaN in the hp column. we will drop those 6 rows. not a good idea under all situation\n",
    "# note: HP is missing because of the non-numeric values in the column\n",
    "# mpg_df = mpg_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b306ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of dropping the rows, lets replace the missing values with the median value.\n",
    "mpg_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values in 'hp' with median value of 'hp' :Note, we do not need to specify the column names\n",
    "# every column's missing values is replaced with that column's median respectively (axis=0 means columnwise )\n",
    "# mpg_df = mpg_df.fillna(mpg_df.median())\n",
    "\n",
    "mpg_df = mpg_df.apply(lambda x:x.fillna(x.median()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4815a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df['hp'] = mpg_df['hp'].astype('float64')   # convering the 'hp' column from object / string type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8521b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us do a correlation analysis among the different dimensions and also each dimension with the dependent dimension\n",
    "# this is done using scatter matrix function which creates a dashboard reflection useful information about the dimension\n",
    "# the result can be stored as a .png file and opened in say, paint to get a larger view\n",
    "\n",
    "mpg_df_attr = mpg_df.iloc[:, 0:10]\n",
    "\n",
    "#axes = pd.plotting.scatter_matrix(mpg_df_attr)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig()\n",
    "\n",
    "sns.pairplot(mpg_df_attr, diag_kind='kde')   # to plot density curve insted of histogram\n",
    "\n",
    "#sns.pairplot(mpg_df_attr)       # to plot histogram, the default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fd036",
   "metadata": {},
   "source": [
    "### The data distribution across various dimensions except 'Acc' do not look normal\n",
    "### Close observation between 'mpg' and other attributes indicate the relationship is not really linear\n",
    "### relation between 'mpg' and 'hp' show hetroscedacity... which will impact model accuracy\n",
    "### How about 'mpg' vs 'yr' surprising to see a positive relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4565330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df.drop('mpg', axis=1)\n",
    "X = X.drop({'origin_america', 'origin_asia', 'origin_europe'}, axis=1)\n",
    "\n",
    "# copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df[['mpg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f694f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us break the X and y dataframe into training set and test set. For this we will use\n",
    "# sklearn package's data splitting function which is based on random function\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and test set in 75:25 ratio \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the LinearRegression function and find the bestfit model on training data\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90842052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us explore the coefficients for each of the independent attribute\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dab767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the intercept for the model\n",
    "\n",
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model score - R2 or coeff of determinant\n",
    "# R^2 = 1 - RSS / TSS = RegErr / TSS\n",
    "\n",
    "regression_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is OLS a good model? should we building a simple linear model ? check the residuals for each predictor\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.residplot(x=X_test['hp'], y=y_test['mpg'], color='green', lowess=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.residplot(x=X_test['acc'], y=y_test['mpg'], color='green', lowess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da318c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the model explains 85% of the variability in Y using X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Using Statmodel library to get R type outputs ----------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 is not a reliable metric as it always increases with addition of more attributes even if the attributes have no\n",
    "# influence on the predicted variable. Instead we use adjusted R^2 which removes the statistical chance that improve R^2\n",
    "# scikit does not provide a facility for adjusted R^2.... so we use\n",
    "# what you obtain in R language\n",
    "# this library expects the X and Y to be given in one single dataframe\n",
    "\n",
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "lm1 = smf.ols(formula= 'mpg ~ cyl+disp+hp+wt+acc+yr+car_type', data = data_train).fit()\n",
    "lm1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe22c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm1.summary())    # inferential statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the sum of squared errors by predicting value of y for test cases and\n",
    "# substracting from the actual y for the test cases\n",
    "\n",
    "mse = np.mean((regression_model.predict(X_test) - y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# underroot of mean_sq_error is standard deviation i.e. avg varience between predicted and actual\n",
    "\n",
    "import math\n",
    "\n",
    "math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d445170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so there is avg of 3.0 (roundoff) mpg difference from rel mpg on an avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict milage (mpg) for a set of attributes not in the training or test set\n",
    "\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this is regression, plot the predicted y value vs actual y values for the test data\n",
    "# A good model's prediction will be close to actual leading to high R and R2 values\n",
    "# plt.rcParam['figure.dpi'] = 500\n",
    "\n",
    "\n",
    "plt.scatter(y_test['mpg'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- ITERATION 2 --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we improve the model ? the R^2 is .844, how do we improve it\n",
    "# The independent attributes have different units and scales of measurement\n",
    "# it is always a good practice to scale all the dimensions using z scores or someother method to address the problem of different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "mpg_df_scaled = mpg_df.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the contents of the dataframe. Check that all the values are now z scores\n",
    "\n",
    "mpg_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df67a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df_scaled.drop('mpg', axis=1)\n",
    "X = X.drop({'origin_america', 'origin_asia', 'origin_europe'}, axis=1)\n",
    "\n",
    "# copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df_scaled[['mpg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and test set in 75:25 ratio \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the LinearRegression function and find the bestfit model on training data\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us explore the coefficients for each of the independent attributes\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model score - R2 or coeff of determinant\n",
    "# R^2=1‚ÄìRSS / TSS\n",
    "\n",
    "regression_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the sum of squared errors by predicting value of y for training cases and \n",
    "# subtracting from the actual y for the training cases\n",
    "\n",
    "mse = np.mean((regression_model.predict(X_test) - y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c635c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# underroot of mean_sq_error is standard deviation i.e. avg variance between predicted and actual\n",
    "\n",
    "import math\n",
    "\n",
    "math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict mileage (mpg) for a set of attributes not in the training or test set\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a83fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is regression, plot the predicted y value vs actual y values for the test data\n",
    "# A good model's prediction will be close to actual leading to high R and R2 values\n",
    "\n",
    "plt.scatter(y_test['mpg'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe2580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
